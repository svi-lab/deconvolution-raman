{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Raman NMF analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This script uses NMF decomposition from Scikit-Learn\n",
    "to produce some informative graphical output on map scans.\n",
    "\n",
    "**ATTENTION:** Since there is no package yet, you need to put the scripts \"read_WDF\" and \"utilities\" in your current working directory.\n",
    "\n",
    "You should first choose the data file with the map scan in the .wdf format.  \n",
    "Then set the initialization dictionary values.\n",
    "\n",
    "_That's it!_\n",
    "___\n",
    "\n",
    "- First plot: (repeated several times troughout the script)  Shows all of your spectra (with navigation buttons)\n",
    "- **Second plot**: Plots each of the components found by NMF\n",
    "- **Third plot**: The heatmap of the mixing coefficients\n",
    "> (shows the abundance of each component troughout the map)  \n",
    "When you double-click on a pixel on this map,\n",
    "it will pop-up another plot\n",
    "showing the spectra recorded at this point,\n",
    "together with the contributions of each component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib tk\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy.signal import savgol_filter, correlate2d\n",
    "from scipy.ndimage import median_filter\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib import colors\n",
    "from matplotlib.widgets import Button\n",
    "import seaborn as sns\n",
    "from tkinter import filedialog, Tk, messagebox\n",
    "from timeit import default_timer as time\n",
    "from read_WDF import convert_time, read_WDF\n",
    "from utilities import NavigationButtons, clean, rolling_median, slice_lr, baseline_als\n",
    "from warnings import warn\n",
    "#import deconvolution\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file: \"carto - 2h_Copy.wdf\"\n",
      "\n",
      "\n",
      "================================= Block : WDF1 =================================\n",
      "size: 512, offset: 0\n",
      "WdfFlag--------------------------------- : \tWdfXYXY\n",
      "PointsPerSpectrum----------------------- : \t891\n",
      "Capacity-------------------------------- : \t20\n",
      "Count----------------------------------- : \t20\n",
      "AccumulationCount----------------------- : \t1\n",
      "YlistLength----------------------------- : \t1\n",
      "XlistLength----------------------------- : \t891\n",
      "DataOriginCount------------------------- : \t5\n",
      "ApplicationName------------------------- : \tWiRE\n",
      "ApplicationVersion---------------------- : \t5.1.0 build 8867\n",
      "ScanType-------------------------------- : \tStatic\n",
      "MeasurementType------------------------- : \tMap\n",
      "StartTime------------------------------- : \tFri Nov 22 16:24:57 2019\n",
      "EndTime--------------------------------- : \tFri Nov 22 16:58:25 2019\n",
      "SpectralUnits--------------------------- : \tCounts\n",
      "LaserWaveLength------------------------- : \t532.06\n",
      "Title----------------------------------- : \tSimple mapping measurement 4\n",
      "\n",
      "================================= Block : WMAP =================================\n",
      "size: 64, offset: 197707\n",
      "MapAreaType----------------------------- : \tRandomPoints\n",
      "InitialCoordinates---------------------- : \t[-19.89 -16.63   0.  ]\n",
      "StepSizes------------------------------- : \t[11. 11.  1.]\n",
      "NbSteps--------------------------------- : \t[5 4 1]\n",
      "LineFocusSize--------------------------- : \t0\n",
      "\n",
      "================================= Block : DATA =================================\n",
      "size: 71296, offset: 512\n",
      "The number of spectra------------------- : \t20\n",
      "The number of points in each spectra---- : \t891\n",
      "\n",
      "================================= Block : XLST =================================\n",
      "size: 3588, offset: 71836\n",
      "The shape of the x_values is------------ : \t(891,)\n",
      "*These are the \"Spectral\" recordings in \"RamanShift\" units\n",
      "\n",
      "================================= Block : YLST =================================\n",
      "size: 28, offset: 71808\n",
      "*No image was recorded\n",
      "\n",
      "================================= Block : ORGN =================================\n",
      "size: 940, offset: 77916\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From .WDF files:\n",
    "\n",
    "data_folder = './Data'\n",
    "prompt_for_images = 'Choose a .wdf file :'\n",
    "# -----------------------Choose a file-----------------------------------------\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "\n",
    "filename, = filedialog.askopenfilenames(initialdir=data_folder,\n",
    "                                        title=prompt_for_images,\n",
    "                                       filetypes=[(\"Wire File\",'.wdf')])\n",
    "\n",
    "\n",
    "# Reading the data from the .wdf file\n",
    "spectra, sigma, params, map_params, origins =\\\n",
    "                            read_WDF(filename, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "- **\"spectra\"** is a 2D numpy array containing the intensities\n",
    "    recorded at each point in a map scan.  \n",
    "    It is of shape:\n",
    "    `(N°_measurement_points, N°_RamanShifts)`\n",
    "- **\"sigma\"** is a 1D numpy array containing all the ramans shift values  \n",
    "    Its' length is `N°_RamanShifts`\n",
    "- **\"params\"** is a dictionnary containing measurement parameters\n",
    "- **\"map_params\"** is dictionnary containing map parameters\n",
    "- **\"origins\"** is a pandas dataframe giving detail on each point in the map scan\n",
    "    (time of measurement, _coordinates and some other info).\n",
    "    \n",
    "> _Note: It should be noted that the timestamp\n",
    "    recorded in the origins dataframe is in the Windows 64bit format,\n",
    "    if you want to convert it to the human readable format,\n",
    "    you can use the imported \"convert_time\" function_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "see_all_spectra = NavigationButtons(sigma, spectra, autoscale_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Initialization\n",
    "_The next cell is basically the only cell you need to modify._\n",
    "\n",
    " - SliceValues: list or tuple of two floats:  Used to isolate the zone you're interested in\n",
    " - NMF_NumberOfComponents: int: Number of components for the NMF decomposition\n",
    " - PCA_components: int or float from the interval [0,1]: number of components to use for the PCA smoothing. If the number given is the positive float<=1, then it is regarded as the ratio of the total variance to preserve after applying the PCA simplification. The algorithm will chose the proper number of components so to cover the given variance ratio.\n",
    " - The last two parameters may help you isolate the physical zone of interest on your map or slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "initialization = {'SliceValues': [160, 1300],  # Use None to count all\n",
    "                  'NMF_NumberOfComponents': 6,\n",
    "                  'PCA_components': 0.998,\n",
    "                  # Put in the int number from 0 to _n_y:\n",
    "                  'NumberOfLinesToSkip_Beggining': 0,\n",
    "                  # Put in the int number from 0 to _n_y - previous element:\n",
    "                  'NumberOfLinesToSkip_End': 0,\n",
    "                  'BaselineCorrection': True,\n",
    "                  'CosmicRayCorrection': False,\n",
    "                  'AbsoluteScale': False}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Pretreatement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "However, if you were to load the data from some other source (like .txt files), it is highely likely that you will not have accès to all the \"metadata\" contained in the original recording. Those concern mainly measurement parameters and map parameters. You should than make the extra effort of providing at least the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the total number of measurement points along x-axis:  5\n",
      "Enter the total number of measurement points along y-axis:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That looks ok.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the size of the step along x-axis:  1\n",
      "Enter the size of the step along y-axis:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# put the retreived number of measurements in a variable\n",
    "# with a shorter name, as it will be used quite often:\n",
    "try:\n",
    "    _n_points = int(params['Count'])\n",
    "except (NameError, KeyError):\n",
    "    _n_points = len(spectra)\n",
    "try:\n",
    "    if params['MeasurementType'] == 'Map':\n",
    "        # Finding in what axes the scan was taken:\n",
    "        _x_index, _y_index = np.where(map_params['NbSteps'] > 1)[0]\n",
    "except (NameError, KeyError):\n",
    "    _x_index, _y_index = 0, 1\n",
    "\n",
    "try:\n",
    "    if params['MeasurementType'] == 'Map':\n",
    "        # ATTENTION : from this point on in the script,\n",
    "        # the two relevant dimensions  will be called\n",
    "        # X and Y regardless if one of them is Z in reality (for slices)\n",
    "        _n_x, _n_y = map_params['NbSteps'][[_x_index, _y_index]]\n",
    "except (NameError, KeyError):\n",
    "    while True:\n",
    "        _n_x = int(input(\"Enter the total number of measurement points along x-axis: \"))\n",
    "        _n_y = int(input(\"Enter the total number of measurement points along y-axis: \"))\n",
    "        if _n_x*_n_y == _n_points:\n",
    "            print(\"That looks ok.\")\n",
    "            break\n",
    "        elif _n_x * _n_y != _n_points:\n",
    "            warn(\"\\nWrong number of points. Try again:\")\n",
    "            continue\n",
    "        break\n",
    "\n",
    "try:\n",
    "    if params['MeasurementType'] == 'Map':    \n",
    "        _s_x, _s_y = map_params['StepSizes'][[_x_index, _y_index]]\n",
    "except (NameError, KeyError):\n",
    "    _s_x = int(input(\"Enter the size of the step along x-axis: \"))\n",
    "    _s_y = int(input(\"Enter the size of the step along y-axis: \"))\n",
    "    print(\"ok\")\n",
    "\n",
    "try:\n",
    "    if params['MeasurementType'] == 'Map':\n",
    "        if (initialization['NumberOfLinesToSkip_Beggining']\n",
    "                + initialization['NumberOfLinesToSkip_End']) > _n_y:\n",
    "            raise SystemExit('You are skiping more lines than present in the scan.\\n'\n",
    "                             'Please revise your initialization parameters')\n",
    "        _n_yy = _n_y - initialization['NumberOfLinesToSkip_End'] -\\\n",
    "                       initialization['NumberOfLinesToSkip_Beggining']\n",
    "    else:\n",
    "        raise SystemExit(\"Can't yet handle this type of scan\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Isolating the part of the spectra that interests us\n",
    "try:\n",
    "    pos_left = initialization[\"SliceValues\"][0]\n",
    "except (NameError, ValueError, TypeError, KeyError):\n",
    "    pos_left = None\n",
    "try:\n",
    "    pos_right = initialization[\"SliceValues\"][1]\n",
    "except (NameError, ValueError, TypeError, KeyError):\n",
    "    pos_right = None\n",
    "spectra_kept, sigma_kept = slice_lr(spectra, sigma,\n",
    "                                    pos_left=pos_left,\n",
    "                                    pos_right=pos_right)\n",
    "\n",
    "# Removing the lines from top and/or bottom of the map\n",
    "try:\n",
    "    skip_lines_up = initialization['NumberOfLinesToSkip_End']\n",
    "except (NameError, ValueError, KeyError):\n",
    "    skip_lines_up = 0\n",
    "_start_pos = skip_lines_up * _n_x\n",
    "\n",
    "try:\n",
    "    skip_lines_down = initialization['NumberOfLinesToSkip_End']\n",
    "except (NameError, ValueError, KeyError):\n",
    "    skip_lines_down = 0\n",
    "\n",
    "if skip_lines_down == 0:\n",
    "    _end_pos = None\n",
    "else:\n",
    "    _end_pos = -np.abs(skip_lines_down) * _n_x\n",
    "\n",
    "spectra_kept = spectra_kept[_start_pos:_end_pos]\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ATTENTION: This next line is likely buggy. The columns containing the coor-\n",
    "# dinates are not necessarily the ones indicated with _x_index ans _y_index!\n",
    "# =============================================================================\n",
    "#_coordinates = origins.iloc[_start_pos:_end_pos, [_x_index+1, _y_index+1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Smoothing using pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "#                                     PCA...\n",
    "# =============================================================================\n",
    "pca = decomposition.PCA(n_components=initialization['PCA_components'])\n",
    "pca_fit = pca.fit(corrected_spectra)\n",
    "#pca_fit.n_components = 0.99#min(initialization['PCA_components'], _n_points, len(sigma_kept))\n",
    "spectra_reduced = pca_fit.transform(corrected_spectra)\n",
    "spectra_denoised = pca_fit.inverse_transform(spectra_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#                  showing the smoothed spectra\n",
    "# =============================================================================\n",
    "\n",
    "_s = np.stack((corrected_spectra, spectra_denoised), axis=-1)\n",
    "check_pca = NavigationButtons(sigma_kept, _s, autoscale_y=True,\n",
    "                                    label=[\"corrected spectra\", \"pca denoised\"],\n",
    "                                    #title=[f\"variance: {pca.explained_variance_ratio_[i]:.3f}\" for i in range(pca.n_components_)],\n",
    "                                    figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Finding the baseline using the asynchronous least squares method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if initialization['BaselineCorrection']:\n",
    "    b_line = baseline_als(spectra_denoised)\n",
    "else:\n",
    "    b_line = np.zeros_like(spectra_kept)\n",
    "\n",
    "# Remove the eventual offsets:\n",
    "corrected_spectra = spectra_denoised - b_line\n",
    "corrected_spectra -= np.min(corrected_spectra, axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Visualise the baseline correction:\n",
    "_baseline_stack = np.stack((spectra_denoised, b_line, corrected_spectra), axis=-1)\n",
    "check_baseline = NavigationButtons(sigma_kept, _baseline_stack, autoscale_y=True,\n",
    "                                   label=['original spectra', 'baseline', 'baseline corrected spectra'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Finding the Cosmic Rays with nearest neghbour and correcting them with median filter\n",
    "**Note:** _This is method is quite robust in finding Cosmic Ray candidates. Nevertheless, some more effort shoud be put in finding a better way of correcting thus found spectra. At the moment, the code simply uses the median value of the neigbourhood._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# This method identifies spectra which differ a lot from their neighbours:\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "prd = clf.fit_predict(corrected_spectra)\n",
    "\n",
    "CR_cand_ind = np.where(prd==-1)[0]\n",
    "\n",
    "print(CR_cand_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "ttt = pairwise_distances(spectra_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.Figure()\n",
    "sns.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if len(CR_cand_ind) > 0:\n",
    "    # Find the median value for each spectra, but only with regard to its' neighbours from the same line\n",
    "    med_spectra_x = rolling_median(corrected_spectra.reshape(_n_yy, _n_x, len(sigma_kept)), w_size=5, ax=1,\n",
    "                               mode='mirror').reshape((-1,len(sigma_kept)))\n",
    "\n",
    "    titles = [f\"candidate from Nearest Neighbour\\noriginal spectra N°{i} \" for i in np.nditer(CR_cand_ind)]\n",
    "    _ss = np.stack((spectra_kept[CR_cand_ind], corrected_spectra[CR_cand_ind], med_spectra_x[CR_cand_ind]), axis=-1)\n",
    "    NavigationButtons(sigma_kept, _ss, autoscale_y=True, title=titles,\n",
    "                      label=['original', 'baseline corrected', 'median correction of CR']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Apply the correction\n",
    "# (just replace the whole spectra containing the cosmic ray with the median spectra of its' neighborhood)\n",
    "if len(CR_cand_ind) > 0:\n",
    "    corrected_spectra[CR_cand_ind] = med_spectra_x[CR_cand_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## The NMF step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting nmf... (be patient, this may take some time...)\n",
      "nmf done in 0.02s\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#                                   NMF step\n",
    "# =============================================================================\n",
    "spectra_cleaned = clean(sigma_kept, spectra_denoised, mode='area')\n",
    "\n",
    "_n_components = initialization['NMF_NumberOfComponents']\n",
    "nmf_model = decomposition.NMF(n_components=_n_components, init='nndsvda', max_iter=7, l1_ratio=1)\n",
    "_start = time()\n",
    "print('starting nmf... (be patient, this may take some time...)')\n",
    "mix = nmf_model.fit_transform(spectra_cleaned)\n",
    "components = nmf_model.components_\n",
    "reconstructed_spectra1 = nmf_model.inverse_transform(mix)\n",
    "_end = time()\n",
    "print(f'nmf done in {_end - _start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#                    preparing the mixture coefficients\n",
    "# =============================================================================\n",
    "\n",
    "mix.resize(int(_n_x*_n_y), _n_components, )\n",
    "_start_pos = initialization['NumberOfLinesToSkip_Beggining'] * _n_x\n",
    "mix = np.roll(mix, _start_pos, axis=0)\n",
    "_comp_area = np.empty(_n_components)\n",
    "for _z in range(_n_components):\n",
    "    # area beneath each component:\n",
    "    _comp_area[_z] = np.trapz(components[_z])#, x=sigma_kept)\n",
    "    components[_z] /= _comp_area[_z]  # normalizing the components by area\n",
    "    # renormalizing the mixture coefficients:\n",
    "    mix[:, _z] *= _comp_area[np.newaxis, _z]\n",
    "mix /= np.sum(mix, axis=-1)[:,np.newaxis]\n",
    "spectra_reconstructed = np.dot(mix, components)\n",
    "_mix_reshaped = mix.reshape(_n_y, _n_x, _n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Main plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "#                    Plotting the components....\n",
    "# =============================================================================\n",
    "sns.set()  # to make plots pretty :)\n",
    "\n",
    "# to keep always the same colors for the same components:\n",
    "col_norm = colors.Normalize(vmin=0, vmax=_n_components)\n",
    "color_set = ScalarMappable(norm=col_norm, cmap=\"brg\")\n",
    "\n",
    "# infer the number of subplots and their disposition from n_components\n",
    "fi, _ax = plt.subplots(int(np.floor(np.sqrt(_n_components))),\n",
    "                       int(np.ceil(_n_components /\n",
    "                                   np.floor(np.sqrt(_n_components))\n",
    "                                   )))\n",
    "if _n_components > 1:\n",
    "    _ax = _ax.ravel()\n",
    "else:\n",
    "    _ax = [_ax]\n",
    "for _i in range(_n_components):\n",
    "    _ax[_i].plot(sigma_kept, components[_i].T, color=color_set.to_rgba(_i))\n",
    "    _ax[_i].set_title(f'Component {_i}')\n",
    "    _ax[_i].set_yticks([])\n",
    "try:\n",
    "    fi.text(0.5, 0.04,\n",
    "            f\"{params['XlistDataType']} recordings\"\n",
    "            f\"in {params['XlistDataUnits']} units\",\n",
    "            ha='center')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "#                       Plotting the main plot...(heatmap)\n",
    "# =============================================================================\n",
    "_n_fig_rows = int(np.floor(np.sqrt(_n_components)))\n",
    "_n_fig_cols = int(np.ceil(_n_components / np.floor(np.sqrt(_n_components))))\n",
    "fig, _ax = plt.subplots(_n_fig_rows, _n_fig_cols,\n",
    "                        sharex=True, sharey=True)\n",
    "if _n_components > 1:\n",
    "    _ax = _ax.ravel()\n",
    "else:\n",
    "    _ax = [_ax]\n",
    "\n",
    "\n",
    "def onclick(event):\n",
    "    '''Double-clicking on a pixel will pop-up the (cleaned) spectrum\n",
    "    corresponding to that pixel, as well as its deconvolution on the components\n",
    "    and again the reconstruction for visual comparison'''\n",
    "    if event.inaxes:\n",
    "        x_pos = int(np.floor(event.xdata))\n",
    "        y_pos = int(np.floor(event.ydata))\n",
    "        broj = int(y_pos*_n_x + x_pos)\n",
    "        spec_num = int(y_pos*_n_x - _start_pos + x_pos)\n",
    "\n",
    "        if event.dblclick:\n",
    "            ff, aa = plt.subplots()\n",
    "            aa.scatter(sigma_kept, spectra_cleaned[spec_num], alpha=0.3,\n",
    "                       label=f'(cleaned) spectrum n°{broj}')\n",
    "            aa.plot(sigma_kept, spectra_reconstructed[broj], '--k',\n",
    "                    label='reconstructed spectrum')\n",
    "            for k in range(_n_components):\n",
    "                aa.plot(sigma_kept, components[k]*mix[broj][k],\n",
    "                        color=color_set.to_rgba(k),\n",
    "                        label=f'Component {k} contribution'\n",
    "                              f'({mix[broj][k]*100:.1f}%)')\n",
    "\n",
    "# This next part is to reorganize the order of labels,\n",
    "# so to put the scatter plot first\n",
    "            handles, labels = aa.get_legend_handles_labels()\n",
    "            order = list(np.arange(_n_components+2))\n",
    "            new_order = [order[-1]]+order[:-1]\n",
    "            aa.legend([handles[idx] for idx in new_order],\n",
    "                      [labels[idx] for idx in new_order])\n",
    "            aa.set_title(f'deconvolution of the spectrum from: '\n",
    "                         f'line {y_pos} & column {x_pos}')\n",
    "            ff.show()\n",
    "    else:\n",
    "        print(\"you clicked outside the canvas, you bastard :)\")\n",
    "\n",
    "\n",
    "_xcolumn_name = ['X', 'Y', 'Z'][_x_index]\n",
    "_ycolumn_name = ['X', 'Y', 'Z'][_y_index]\n",
    "\n",
    "#################################################################################\n",
    "############## This formatting should be adapted case by case ###################\n",
    "try:\n",
    "    _y_ticks = [str(int(x/1000))+'mm' for x in\n",
    "                np.asarray(origins[_ycolumn_name].iloc[:_n_x*_n_y:_n_x])]\n",
    "    _x_ticks = [str(int(x/1000))+'mm' for x in\n",
    "                np.asarray(origins[_xcolumn_name].iloc[:_n_x])]\n",
    "except:\n",
    "    pass\n",
    "#################################################################################\n",
    "if initialization['AbsoluteScale'] == True:\n",
    "    scaling = {'vmin': 0, 'vmax': 1}\n",
    "else:\n",
    "    scaling={}\n",
    "\n",
    "for _i in range(_n_components):\n",
    "    sns.heatmap(_mix_reshaped[:, :, _i], ax=_ax[_i], cmap=\"jet\", annot=False, **scaling)\n",
    "#    _ax[_i].set_aspect(_s_y/_s_x)\n",
    "    _ax[_i].set_title(f'Component {_i}', color=color_set.to_rgba(_i),\n",
    "                      fontweight='extra bold')\n",
    "fig.suptitle('Heatmaps showing the abundance of individual components'\n",
    "             ' throughout the scanned area.')\n",
    "fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Appendix - save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#        saving some data for usage in other software (Origin, Excel..)\n",
    "# =============================================================================\n",
    "_basic_mix = pd.DataFrame(\n",
    "        np.copy(mix),\n",
    "        columns=[f\"mixing coeff. for the component {l}\"\n",
    "                 for l in np.arange(mix.shape[1])]\n",
    "        )\n",
    "_save_filename_extension = (f\"_{_n_components}NMFcomponents_from\"\n",
    "                            f\".csv\")\n",
    "_save_filename_folder = '/'.join(x for x in filename.split('/')[:-1])+'/'\\\n",
    "                        + filename.split('/')[-1][:-4]+'/'\n",
    "if not os.path.exists(_save_filename_folder):\n",
    "    os.mkdir(_save_filename_folder)\n",
    "\n",
    "_basic_mix.to_csv(\n",
    "        f\"{_save_filename_folder}MixingCoeffs{_save_filename_extension}\",\n",
    "        sep=';', index=False)\n",
    "_save_components = pd.DataFrame(\n",
    "        components.T, index=sigma_kept,\n",
    "        columns=[f\"Component{_i}\" for _i in np.arange(_n_components)])\n",
    "_save_components.index.name = 'Raman shift in cm-1'\n",
    "_save_components.to_csv(\n",
    "        f\"{_save_filename_folder}Components{_save_filename_extension}\",\n",
    "        sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pca_err = np.sum(np.abs(corrected_spectra - spectra_denoised), axis=1)\n",
    "pca_err.resize(_n_y, _n_x)\n",
    "plt.figure()\n",
    "sns.heatmap(pca_err)#, vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D",
   "language": "python",
   "name": "3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
