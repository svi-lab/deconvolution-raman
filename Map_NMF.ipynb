{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raman NMF analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses NMF decomposition from Scikit-Learn\n",
    "to produce some informative graphical output on map scans.\n",
    "\n",
    "**ATTENTION:** Since there is no package yet, you need to put the scripts \"read_WDF\" and \"utilities\" in your current working directory.\n",
    "\n",
    "You should first choose the data file with the map scan in the .wdf format.  \n",
    "Then set the initialization dictionary values.\n",
    "\n",
    "_That's it!_\n",
    "___\n",
    "\n",
    "- First plot: (repeated several times troughout the script)  Shows all of your spectra (with navigation buttons)\n",
    "- **Second plot**: Plots each of the components found by NMF\n",
    "- **Third plot**: The heatmap of the mixing coefficients\n",
    "> (shows the abundance of each component troughout the map)  \n",
    "When you double-click on a pixel on this map,\n",
    "it will pop-up another plot\n",
    "showing the spectra recorded at this point,\n",
    "together with the contributions of each component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file: \"exampleA1.wdf\"\n",
      "\n",
      "\n",
      "================================= Block : WDF1 =================================\n",
      "size: 512, offset: 0\n",
      "WdfFlag--------------------------------- : \tWdfXYXY\n",
      "PointsPerSpectrum----------------------- : \t1015\n",
      "Capacity-------------------------------- : \t2006\n",
      "Count----------------------------------- : \t2006\n",
      "AccumulationCount----------------------- : \t1\n",
      "YlistLength----------------------------- : \t1\n",
      "XlistLength----------------------------- : \t1015\n",
      "DataOriginCount------------------------- : \t9\n",
      "ApplicationName------------------------- : \tWiRE\n",
      "ApplicationVersion---------------------- : \t5.3.0 build 16195\n",
      "ScanType-------------------------------- : \tStreamLineHR\n",
      "MeasurementType------------------------- : \tMap\n",
      "StartTime------------------------------- : \tMon Jun 21 08:06:02 2021\n",
      "EndTime--------------------------------- : \tMon Jun 21 12:35:25 2021\n",
      "SpectralUnits--------------------------- : \tCounts\n",
      "LaserWaveLength------------------------- : \t532.06\n",
      "Title----------------------------------- : \tStreamHR image acquisition\n",
      "\n",
      "================================= Block : WMAP =================================\n",
      "size: 64, offset: 8702361\n",
      "MapAreaType----------------------------- : \tRandomPoints\n",
      "InitialCoordinates---------------------- : \t[-28.4 -16.4   0. ]\n",
      "StepSizes------------------------------- : \t[1. 1. 1.]\n",
      "NbSteps--------------------------------- : \t[59 34  1]\n",
      "LineFocusSize--------------------------- : \t0\n",
      "\n",
      "================================= Block : DATA =================================\n",
      "size: 8144376, offset: 512\n",
      "The number of spectra------------------- : \t2006\n",
      "The number of points in each spectra---- : \t1015\n",
      "\n",
      "================================= Block : XLST =================================\n",
      "size: 4084, offset: 8144916\n",
      "The shape of the x_values is------------ : \t(1015,)\n",
      "*These are the \"Spectral\" recordings in \"RamanShift\" units\n",
      "\n",
      "================================= Block : YLST =================================\n",
      "size: 28, offset: 8144888\n",
      "*No image was recorded\n",
      "\n",
      "================================= Block : ORGN =================================\n",
      "size: 144668, offset: 8151949\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib tk\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy.signal import savgol_filter, correlate2d\n",
    "from scipy.ndimage import median_filter\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib import colors\n",
    "from matplotlib.widgets import Button\n",
    "import seaborn as sns\n",
    "from tkinter import filedialog, Tk, messagebox\n",
    "from timeit import default_timer as time\n",
    "from read_WDF import convert_time, read_WDF\n",
    "from utilities import NavigationButtons, clean, rolling_median, slice_lr, baseline_als\n",
    "from warnings import warn\n",
    "#import deconvolution\n",
    "\n",
    "sns.set()\n",
    "\n",
    "## Loading Data\n",
    "\n",
    "# From .WDF files:\n",
    "\n",
    "data_folder = '../../RamanData'\n",
    "prompt_for_images = 'Choose a .wdf file :'\n",
    "# -----------------------Choose a file-----------------------------------------\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "\n",
    "filename, = filedialog.askopenfilenames(initialdir=data_folder,\n",
    "                                        title=prompt_for_images,\n",
    "                                       filetypes=[(\"Wire File\",'.wdf')])\n",
    "\n",
    "\n",
    "# Reading the data from the .wdf file\n",
    "spectra, sigma, params, map_params, origins =\\\n",
    "                            read_WDF(filename, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R (Counts)</th>\n",
       "      <th>X (Micron)</th>\n",
       "      <th>Y (Micron)</th>\n",
       "      <th>Z (Micron)</th>\n",
       "      <th>Time (FileTime)</th>\n",
       "      <th>Flags (Arbitrary)</th>\n",
       "      <th>Checksum (Arbitrary)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-700.0</td>\n",
       "      <td>1.326159e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-700.0</td>\n",
       "      <td>1.326159e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-700.0</td>\n",
       "      <td>1.326159e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-700.0</td>\n",
       "      <td>1.326159e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-700.0</td>\n",
       "      <td>1.326159e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-350.0</td>\n",
       "      <td>1.326164e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-350.0</td>\n",
       "      <td>1.326164e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-350.0</td>\n",
       "      <td>1.326164e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-350.0</td>\n",
       "      <td>1.326164e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-350.0</td>\n",
       "      <td>1.326164e+17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     R (Counts)  X (Micron)  Y (Micron)  Z (Micron)  Time (FileTime)  \\\n",
       "0           0.0         0.0         0.0      -700.0     1.326159e+17   \n",
       "1          10.0        10.0         0.0      -700.0     1.326159e+17   \n",
       "2          20.0        20.0         0.0      -700.0     1.326159e+17   \n",
       "3          30.0        30.0         0.0      -700.0     1.326159e+17   \n",
       "4          40.0        40.0         0.0      -700.0     1.326159e+17   \n",
       "..          ...         ...         ...         ...              ...   \n",
       "571       110.0       110.0         0.0      -350.0     1.326164e+17   \n",
       "572       120.0       120.0         0.0      -350.0     1.326164e+17   \n",
       "573       130.0       130.0         0.0      -350.0     1.326164e+17   \n",
       "574       140.0       140.0         0.0      -350.0     1.326164e+17   \n",
       "575       150.0       150.0         0.0      -350.0     1.326164e+17   \n",
       "\n",
       "     Flags (Arbitrary)  Checksum (Arbitrary)  \n",
       "0                  0.0                   0.0  \n",
       "1                  0.0                   0.0  \n",
       "2                  0.0                   0.0  \n",
       "3                  0.0                   0.0  \n",
       "4                  0.0                   0.0  \n",
       "..                 ...                   ...  \n",
       "571                0.0                   0.0  \n",
       "572                0.0                   0.0  \n",
       "573                0.0                   0.0  \n",
       "574                0.0                   0.0  \n",
       "575                0.0                   0.0  \n",
       "\n",
       "[576 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origins.loc[:, \"R (Counts)\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **\"spectra\"** is a 2D numpy array containing the intensities\n",
    "    recorded at each point in a map scan.  \n",
    "    It is of shape:\n",
    "    `(N°_measurement_points, N°_RamanShifts)`\n",
    "- **\"sigma\"** is a 1D numpy array containing all the ramans shift values  \n",
    "    Its' length is `N°_RamanShifts`\n",
    "- **\"params\"** is a dictionnary containing measurement parameters\n",
    "- **\"map_params\"** is dictionnary containing map parameters\n",
    "- **\"origins\"** is a pandas dataframe giving detail on each point in the map scan\n",
    "    (time of measurement, _coordinates and some other info).\n",
    "    \n",
    "> _Note: It should be noted that the timestamp\n",
    "    recorded in the origins dataframe is in the Windows 64bit format,\n",
    "    if you want to convert it to the human readable format,\n",
    "    you can use the imported \"convert_time\" function_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert params.get('MeasurementType', 'Not a map') == 'Map', \"This script is only intened to be used on maps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "_The next cell is basically the only cell you need to modify._\n",
    "\n",
    " - SliceValues: list or tuple of two floats:  Used to isolate the zone you're interested in\n",
    " - NMF_NumberOfComponents: int: Number of components for the NMF decomposition\n",
    " - PCA_components: int or float from the interval [0,1]: number of components to use for the PCA smoothing. If the number given is the positive float<=1, then it is regarded as the ratio of the total variance to preserve after applying the PCA simplification. The algorithm will chose the proper number of components so to cover the given variance ratio.\n",
    " - The last two parameters may help you isolate the physical zone of interest on your map or slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization = {'SliceValues': None,#[400, None],#[350, 1300], # Use None to count all\n",
    "                  'NMF_NumberOfComponents': 3,\n",
    "                  'PCA_components': 15,#0.998,\n",
    "                  # Put in the int number from 0 to _n_y:\n",
    "                  'NumberOfLinesToSkip_Beggining': 0,\n",
    "                  # Put in the int number from 0 to _n_y - previous element:\n",
    "                  'NumberOfLinesToSkip_End': 0,\n",
    "                  'BaselineCorrection': False,\n",
    "                  'CosmicRayCorrection': False,\n",
    "                  # Nearest neighbour method\n",
    "                  # To use only in maps where step sizes are smaller then\n",
    "                  # Sample's feature sizes (oversampled maps)\n",
    "                  'AbsoluteScale': False,  # what type of colorbar to use\n",
    "                  \"save_data\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretreatement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you were to load the data from some other source (like .txt files), it is highely likely that you will not have accès to all the \"metadata\" contained in the original recording. Those concern mainly measurement parameters and map parameters. You should than make the extra effort of providing at least the following:  \n",
    "    - `_n_x` and `_n_y` (the number of points in each dimension of the map)  \n",
    "    - `_s_x` and `_s_y` (step sizes in each dimension of the map)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the retreived number of measurements in a variable\n",
    "# with a shorter name, as it will be used quite often:\n",
    "try:\n",
    "    _n_points = int(params['Count'])\n",
    "except (NameError, KeyError):\n",
    "    print(f\"We'll consider having a total of {len(spectra)} points in your map\")\n",
    "    _n_points = len(spectra)\n",
    "try:\n",
    "    # Finding in what axes the scan was taken:\n",
    "    _x_index, _y_index = np.where(map_params['NbSteps'] > 1)[0]\n",
    "except (NameError, KeyError):\n",
    "    _x_index, _y_index = 0, 1\n",
    "\n",
    "try:\n",
    "    # ATTENTION : from this point on in the script,\n",
    "    # the two relevant dimensions  will be called X and Y\n",
    "    # regardless if one of them is Z in reality (for slices)\n",
    "    _n_x, _n_y = map_params['NbSteps'][[_x_index, _y_index]]\n",
    "except (NameError, KeyError):\n",
    "    while True:\n",
    "        _n_x = int(input(\"Enter the total number of measurement points along x-axis: \"))\n",
    "        _n_y = int(input(\"Enter the total number of measurement points along y-axis: \"))\n",
    "        if _n_x*_n_y == _n_points:\n",
    "            print(\"That looks ok.\")\n",
    "            break\n",
    "        elif _n_x * _n_y != _n_points:\n",
    "            warn(\"\\nWrong number of points. Try again:\")\n",
    "            continue\n",
    "        break\n",
    "\n",
    "try:\n",
    "    _s_x, _s_y = map_params['StepSizes'][[_x_index, _y_index]]\n",
    "except (NameError, KeyError):\n",
    "    _s_x = int(input(\"Enter the size of the step along x-axis: \"))\n",
    "    _s_y = int(input(\"Enter the size of the step along y-axis: \"))\n",
    "    print(\"ok\")\n",
    "\n",
    "\n",
    "### Slicing\n",
    "\n",
    "# Isolating the part of the spectra that interests us\n",
    "try:\n",
    "    pos_left = initialization[\"SliceValues\"][0]\n",
    "except (NameError, ValueError, TypeError, KeyError):\n",
    "    pos_left = None\n",
    "try:\n",
    "    pos_right = initialization[\"SliceValues\"][1]\n",
    "except (NameError, ValueError, TypeError, KeyError):\n",
    "    pos_right = None\n",
    "spectra_kept, sigma_kept = slice_lr(spectra, sigma,\n",
    "                                    pos_left=pos_left,\n",
    "                                    pos_right=pos_right)\n",
    "\n",
    "# Removing the lines from top and/or bottom of the map\n",
    "try:\n",
    "    skip_lines_up = initialization['NumberOfLinesToSkip_End']\n",
    "except (NameError, ValueError, KeyError):\n",
    "    skip_lines_up = 0\n",
    "_start_pos = skip_lines_up * _n_x\n",
    "try:\n",
    "    skip_lines_down = initialization['NumberOfLinesToSkip_End']\n",
    "except (NameError, ValueError, KeyError):\n",
    "    skip_lines_down = 0\n",
    "if skip_lines_down == 0:\n",
    "    _end_pos = None\n",
    "else:\n",
    "    _end_pos = -np.abs(skip_lines_down) * _n_x\n",
    "    \n",
    "skipped_lines_total = skip_lines_up + np.abs(skip_lines_down)\n",
    "\n",
    "if skipped_lines_total > _n_y:\n",
    "    raise SystemExit('You are skiping more lines than present in the scan.\\n'\n",
    "                     'Please revise your initialization parameters')\n",
    "else:\n",
    "    spectra_kept = spectra_kept[_start_pos:_end_pos]\n",
    "    _n_yy = _n_y - skipped_lines_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_n_x, _n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "#                                     PCA...\n",
    "# =============================================================================\n",
    "pca = decomposition.PCA(n_components=initialization['PCA_components'])\n",
    "pca_fit = pca.fit(spectra_kept)\n",
    "#pca_fit.n_components = 0.99#min(initialization['PCA_components'], _n_points, len(sigma_kept))\n",
    "spectra_reduced = pca_fit.transform(spectra_kept)\n",
    "spectra_denoised = pca_fit.inverse_transform(spectra_reduced)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#                  showing the smoothed spectra\n",
    "# =============================================================================\n",
    "\n",
    "_s = np.stack((spectra_kept, spectra_denoised), axis=-1)\n",
    "check_pca = NavigationButtons(sigma_kept, _s, autoscale_y=True,\n",
    "                                    label=[\"original spectra\", \"pca denoised\"],\n",
    "                                    #title=[f\"variance: {pca.explained_variance_ratio_[i]:.3f}\" for i in range(pca.n_components_)],\n",
    "                                    figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_reduced.shape, novica.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = np.ones(15, dtype=bool)\n",
    "valid_idx[5:8] = 0\n",
    "novica = pca.mean_ + np.dot(spectra_reduced[:, valid_idx], pca.components_[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.AllMaps(novica.reshape(_n_y, _n_x, -1), sigma=sigma_kept)#, components=pca.components_[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.stack((spectra_denoised, spectra_kept, novica), axis=-1 )\n",
    "ut.NavigationButtons(sigma_kept, ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the baseline using the asynchronous least squares method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if initialization['BaselineCorrection']:\n",
    "    b_line = baseline_als(spectra_denoised, lam=4e3)\n",
    "else:\n",
    "    b_line = np.zeros_like(spectra_kept)\n",
    "\n",
    "# Remove the eventual offsets:\n",
    "corrected_spectra = spectra_denoised - b_line\n",
    "corrected_spectra -= np.min(corrected_spectra, axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the baseline correction:\n",
    "_baseline_stack = np.stack((spectra_denoised, b_line, corrected_spectra), axis=-1)\n",
    "check_baseline = NavigationButtons(sigma_kept, _baseline_stack, autoscale_y=True,\n",
    "                                   label=['original spectra', 'baseline', 'baseline corrected spectra'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Cosmic Rays with nearest neghbour and correcting them with median filter\n",
    "**Note:** _This is method is quite robust in finding Cosmic Ray candidates. Nevertheless, some more effort shoud be put in finding a better way of correcting thus found spectra. At the moment, the code simply uses the median value of the neigbourhood._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method identifies spectra which differ a lot from their neighbours:\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "prd = clf.fit_predict(corrected_spectra)\n",
    "\n",
    "CR_cand_ind = np.where(prd==-1)[0]\n",
    "\n",
    "print(CR_cand_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(CR_cand_ind) > 0:\n",
    "    # Find the median value for each spectra, but only with regard to its' neighbours from the same line\n",
    "    med_spectra_x = rolling_median(corrected_spectra.reshape(_n_yy, _n_x, len(sigma_kept)), w_size=5, ax=1,\n",
    "                               mode='mirror').reshape((-1,len(sigma_kept)))\n",
    "\n",
    "    titles = [f\"candidate from Nearest Neighbour\\noriginal spectra N°{i} \" for i in np.nditer(CR_cand_ind)]\n",
    "    _ss = np.stack((spectra_kept[CR_cand_ind], corrected_spectra[CR_cand_ind], med_spectra_x[CR_cand_ind]), axis=-1)\n",
    "    NavigationButtons(sigma_kept, _ss, autoscale_y=True, title=titles,\n",
    "                      label=['original', 'baseline corrected', 'median correction of CR']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the correction\n",
    "# (just replace the whole spectra containing the cosmic ray with the median spectra of its' neighborhood)\n",
    "if len(CR_cand_ind) > 0:\n",
    "    corrected_spectra[CR_cand_ind] = med_spectra_x[CR_cand_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NMF step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#                                   NMF step\n",
    "# =============================================================================\n",
    "spectra_cleaned = clean(sigma_kept, spectra_denoised, mode='area')\n",
    "\n",
    "_n_components = initialization['NMF_NumberOfComponents']\n",
    "nmf_model = decomposition.NMF(n_components=_n_components, init='nndsvda', max_iter=7, l1_ratio=1)\n",
    "_start = time()\n",
    "print('starting nmf... (be patient, this may take some time...)')\n",
    "mix = nmf_model.fit_transform(spectra_cleaned)\n",
    "components = nmf_model.components_\n",
    "reconstructed_spectra1 = nmf_model.inverse_transform(mix)\n",
    "_end = time()\n",
    "print(f'nmf done in {_end - _start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#                    preparing the mixture coefficients\n",
    "# =============================================================================\n",
    "\n",
    "mix.resize(int(_n_x*_n_y), _n_components, )\n",
    "_start_pos = initialization['NumberOfLinesToSkip_Beggining'] * _n_x\n",
    "mix = np.roll(mix, _start_pos, axis=0)\n",
    "_comp_area = np.empty(_n_components)\n",
    "for _z in range(_n_components):\n",
    "    # area beneath each component:\n",
    "    _comp_area[_z] = np.trapz(components[_z])#, x=sigma_kept)\n",
    "    components[_z] /= _comp_area[_z]  # normalizing the components by area\n",
    "    # renormalizing the mixture coefficients:\n",
    "    mix[:, _z] *= _comp_area[np.newaxis, _z]\n",
    "mix /= np.sum(mix, axis=-1)[:,np.newaxis]\n",
    "spectra_reconstructed = np.dot(mix, components)\n",
    "_mix_reshaped = mix.reshape(_n_y, _n_x, _n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "#                    Plotting the components....\n",
    "# =============================================================================\n",
    "sns.set()  # to make plots pretty :)\n",
    "\n",
    "# to keep always the same colors for the same components:\n",
    "col_norm = colors.Normalize(vmin=0, vmax=_n_components)\n",
    "color_set = ScalarMappable(norm=col_norm, cmap=\"brg\")\n",
    "\n",
    "# infer the number of subplots and their disposition from n_components\n",
    "fi, _ax = plt.subplots(int(np.floor(np.sqrt(_n_components))),\n",
    "                       int(np.ceil(_n_components /\n",
    "                                   np.floor(np.sqrt(_n_components))\n",
    "                                   )))\n",
    "if _n_components > 1:\n",
    "    _ax = _ax.ravel()\n",
    "else:\n",
    "    _ax = [_ax]\n",
    "for _i in range(_n_components):\n",
    "    _ax[_i].plot(sigma_kept, components[_i].T, color=color_set.to_rgba(_i))\n",
    "    _ax[_i].set_title(f'Component {_i}')\n",
    "    _ax[_i].set_yticks([])\n",
    "try:\n",
    "    fi.text(0.5, 0.04,\n",
    "            f\"{params['XlistDataType']} recordings\"\n",
    "            f\"in {params['XlistDataUnits']} units\",\n",
    "            ha='center')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "#                       Plotting the main plot...(heatmap)\n",
    "# =============================================================================\n",
    "_n_fig_rows = int(np.floor(np.sqrt(_n_components)))\n",
    "_n_fig_cols = int(np.ceil(_n_components / np.floor(np.sqrt(_n_components))))\n",
    "fig, _ax = plt.subplots(_n_fig_rows, _n_fig_cols,\n",
    "                        sharex=True, sharey=True)\n",
    "if _n_components > 1:\n",
    "    _ax = _ax.ravel()\n",
    "else:\n",
    "    _ax = [_ax]\n",
    "\n",
    "\n",
    "def onclick(event):\n",
    "    '''Double-clicking on a pixel will pop-up the (cleaned) spectrum\n",
    "    corresponding to that pixel, as well as its deconvolution on the components\n",
    "    and again the reconstruction for visual comparison'''\n",
    "    if event.inaxes:\n",
    "        x_pos = np.round(event.xdata))\n",
    "        y_pos = np.round(event.ydata))\n",
    "        broj = np.round(y_pos*_n_x + x_pos)\n",
    "        spec_num = np.round(y_pos*_n_x - _start_pos + x_pos)\n",
    "\n",
    "        if event.dblclick:\n",
    "            ff, aa = plt.subplots()\n",
    "            aa.scatter(sigma_kept, spectra_cleaned[spec_num], alpha=0.3,\n",
    "                       label=f'(cleaned) spectrum n°{broj}')\n",
    "            aa.plot(sigma_kept, spectra_reconstructed[broj], '--k',\n",
    "                    label='reconstructed spectrum')\n",
    "            for k in range(_n_components):\n",
    "                aa.plot(sigma_kept, components[k]*mix[broj][k],\n",
    "                        color=color_set.to_rgba(k),\n",
    "                        label=f'Component {k} contribution'\n",
    "                              f'({mix[broj][k]*100:.1f}%)')\n",
    "\n",
    "# This next part is to reorganize the order of labels,\n",
    "# so to put the scatter plot first\n",
    "            handles, labels = aa.get_legend_handles_labels()\n",
    "            order = list(np.arange(_n_components+2))\n",
    "            new_order = [order[-1]]+order[:-1]\n",
    "            aa.legend([handles[idx] for idx in new_order],\n",
    "                      [labels[idx] for idx in new_order])\n",
    "            aa.set_title(f'deconvolution of the spectrum from: '\n",
    "                         f'line {y_pos} & column {x_pos}')\n",
    "            ff.show()\n",
    "    else:\n",
    "        print(\"you clicked outside the canvas, you bastard :)\")\n",
    "\n",
    "\n",
    "_xcolumn_name = ['X', 'Y', 'Z'][_x_index]\n",
    "_ycolumn_name = ['X', 'Y', 'Z'][_y_index]\n",
    "\n",
    "#################################################################################\n",
    "############## This formatting should be adapted case by case ###################\n",
    "try:\n",
    "    _y_ticks = [str(int(x/1000))+'mm' for x in\n",
    "                np.asarray(origins[_ycolumn_name].iloc[:_n_x*_n_y:_n_x])]\n",
    "    _x_ticks = [str(int(x/1000))+'mm' for x in\n",
    "                np.asarray(origins[_xcolumn_name].iloc[:_n_x])]\n",
    "except:\n",
    "    pass\n",
    "#################################################################################\n",
    "if initialization['AbsoluteScale'] == True:\n",
    "    scaling = {'vmin': 0, 'vmax': 1}\n",
    "else:\n",
    "    scaling={}\n",
    "\n",
    "for _i in range(_n_components):\n",
    "    sns.heatmap(_mix_reshaped[:, :, _i], ax=_ax[_i], cmap=\"jet\", annot=False, **scaling)\n",
    "#    _ax[_i].set_aspect(_s_y/_s_x)\n",
    "    _ax[_i].set_title(f'Component {_i}', color=color_set.to_rgba(_i),\n",
    "                      fontweight='extra bold')\n",
    "fig.suptitle('Heatmaps showing the abundance of individual components'\n",
    "             ' throughout the scanned area.')\n",
    "fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#        saving some data for usage in other software (Origin, Excel..)\n",
    "# =============================================================================\n",
    "_basic_mix = pd.DataFrame(\n",
    "        np.copy(mix),\n",
    "        columns=[f\"mixing coeff. for the component {l}\"\n",
    "                 for l in np.arange(mix.shape[1])]\n",
    "        )\n",
    "_save_filename_extension = (f\"_{_n_components}NMFcomponents_from\"\n",
    "                            f\".csv\")\n",
    "_save_filename_folder = '/'.join(x for x in filename.split('/')[:-1])+'/'\\\n",
    "                        + filename.split('/')[-1][:-4]+'/'\n",
    "if not os.path.exists(_save_filename_folder):\n",
    "    os.mkdir(_save_filename_folder)\n",
    "\n",
    "_basic_mix.to_csv(\n",
    "        f\"{_save_filename_folder}MixingCoeffs{_save_filename_extension}\",\n",
    "        sep=';', index=False)\n",
    "_save_components = pd.DataFrame(\n",
    "        components.T, index=sigma_kept,\n",
    "        columns=[f\"Component{_i}\" for _i in np.arange(_n_components)])\n",
    "_save_components.index.name = 'Raman shift in cm-1'\n",
    "_save_components.to_csv(\n",
    "        f\"{_save_filename_folder}Components{_save_filename_extension}\",\n",
    "        sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_err = np.sum(np.abs(corrected_spectra - spectra_denoised), axis=1)\n",
    "pca_err.resize(_n_y, _n_x)\n",
    "plt.figure()\n",
    "sns.heatmap(pca_err)#, vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Raman",
   "language": "python",
   "name": "raman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
